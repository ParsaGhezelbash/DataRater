{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04fc1ff4-b1b9-4066-936c-dbdee2178553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import numpy as np\n",
    "from scipy import stats # Import the stats module from SciPy\n",
    "\n",
    "from models import construct_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae88fb3-c0d6-4491-ad00-334796fd016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Pipeline ---\n",
    "def get_mnist_loaders(batch_size):\n",
    "    \"\"\"Prepares the MNIST train, validation, and test data loaders.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf40e3e7-93a8-4ab0-94c1-7f74540b451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_images(images, corruption_fraction):\n",
    "    \"\"\"\n",
    "    Corrupts a batch of images by REPLACING a fraction of pixels with random noise.\n",
    "    Args:\n",
    "        images (torch.Tensor): A batch of images (B, C, H, W).\n",
    "        corruption_fraction (float): The fraction of pixels to corrupt (0.0 to 1.0).\n",
    "    Returns:\n",
    "        torch.Tensor: The batch of corrupted images.\n",
    "    \"\"\"\n",
    "    if corruption_fraction == 0.0:\n",
    "        return images\n",
    "\n",
    "    corrupted_images = images.clone()\n",
    "    batch_size, _, height, width = images.shape\n",
    "    num_pixels_total = height * width\n",
    "    num_pixels_to_corrupt = int(corruption_fraction * num_pixels_total)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Generate a random permutation of pixel indices to corrupt\n",
    "        indices = torch.randperm(num_pixels_total, device=images.device)[:num_pixels_to_corrupt]\n",
    "\n",
    "        # Convert flat indices to 2D indices\n",
    "        row_indices = indices // width\n",
    "        col_indices = indices % width\n",
    "\n",
    "        # --- Generate random pixel values to replace the existing ones ---\n",
    "        # Values are from a uniform distribution across the full [-1, 1] range.\n",
    "        random_pixels = torch.rand(num_pixels_to_corrupt, device=images.device) * 2 - 1\n",
    "\n",
    "        # --- Place the new random pixels into the image ---\n",
    "        corrupted_images[i, 0, row_indices, col_indices] = random_pixels\n",
    "\n",
    "    return corrupted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da09ca4e-cd19-4098-ace7-7c9af327ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_with_individual_corruption(data_rater, data_loader, num_batches=5, current_step=None):\n",
    "    \"\"\"\n",
    "    Analyzes the DataRater by corrupting each image with a continuous random\n",
    "    fraction and creating a scatter plot of scores vs. corruption.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Analyzing with Continuous Individual Corruption over {num_batches} batches --- MetaStep: {current_step}\")\n",
    "    data_rater.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # These master lists will store the results from all batches\n",
    "    all_scores = []\n",
    "    all_fractions = []\n",
    "\n",
    "    # Loop over the specified number of batches\n",
    "    for i, (batch_images, _) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "\n",
    "        batch_images = batch_images.to(DEVICE)\n",
    "        batch_size = batch_images.size(0)\n",
    "\n",
    "        individually_corrupted_batch = torch.zeros_like(batch_images)\n",
    "        fractions_for_this_batch = []\n",
    "\n",
    "        # Corrupt each image in the batch one by one\n",
    "        for j in range(batch_size):\n",
    "            # --- NEW: Generate a continuous random fraction between 0.0 and 1.0 ---\n",
    "            frac = np.random.uniform(0.0, 1.0)\n",
    "            fractions_for_this_batch.append(frac)\n",
    "\n",
    "            # Corrupt the single image (note: we keep the batch dimension)\n",
    "            original_image = batch_images[j:j+1]\n",
    "            corrupted_image = corrupt_images(original_image, frac)\n",
    "            individually_corrupted_batch[j] = corrupted_image\n",
    "\n",
    "        # Get the model's scores for the entire batch of individually corrupted images\n",
    "        with torch.no_grad():\n",
    "            scores = data_rater(individually_corrupted_batch)\n",
    "            weights = torch.softmax(scores, dim=0)\n",
    "\n",
    "        # Append the results to our master lists\n",
    "        all_scores.extend(weights.cpu().numpy())\n",
    "        all_fractions.extend(fractions_for_this_batch)\n",
    "\n",
    "    # --- Plotting and Regression Analysis ---\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Scatter plot with continuous x-axis values (jitter is no longer needed)\n",
    "    plt.scatter(all_fractions, all_scores, alpha=0.3, label='Individual Image Score')\n",
    "\n",
    "    # Perform and plot the linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(all_fractions, all_scores)\n",
    "    r_squared = r_value**2\n",
    "\n",
    "    x_line = np.array([min(all_fractions), max(all_fractions)])\n",
    "    y_line = slope * x_line + intercept\n",
    "\n",
    "    plt.plot(x_line, y_line,\n",
    "             color='red', linewidth=2,\n",
    "             label=f'Linear Regression (RÂ² = {r_squared:.3f})')\n",
    "\n",
    "    plt.title('DataRater Score vs. Individual Image Corruption', fontsize=16)\n",
    "    plt.xlabel('Fraction of Corrupted Pixels')\n",
    "    plt.ylabel('Raw Score (Rating)')\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28485f47-a9c2-438f-bccf-be168e7bd3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_corruption(data_rater, data_loader, num_images=5):\n",
    "    \"\"\"\n",
    "    Selects images, displays them with varying corruption, and overlays the\n",
    "    DataRater's score on each image.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Visualizing Image Corruption with DataRater Scores ---\")\n",
    "\n",
    "    # Ensure the model is on the correct device and in evaluation mode\n",
    "    data_rater.to(DEVICE).eval()\n",
    "\n",
    "    # Get a single batch of images\n",
    "    sample_images, _ = next(iter(data_loader))\n",
    "\n",
    "    corruption_fractions = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "    fig, axes = plt.subplots(num_images, len(corruption_fractions), figsize=(12, num_images * 2.2))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        original_image = sample_images[i:i+1]  # Keep batch dim\n",
    "\n",
    "        for j, frac in enumerate(corruption_fractions):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            # Create the corrupted version\n",
    "            corrupted_image_tensor = corrupt_images(original_image, frac)\n",
    "\n",
    "            # --- Get the DataRater's score for this specific image ---\n",
    "            with torch.no_grad():\n",
    "                score = data_rater(corrupted_image_tensor.to(DEVICE)).item()\n",
    "\n",
    "            # Prepare image for plotting (denormalize, etc.)\n",
    "            img_to_plot = corrupted_image_tensor.squeeze().cpu().numpy()\n",
    "            img_to_plot = img_to_plot * 0.5 + 0.5\n",
    "\n",
    "            ax.imshow(img_to_plot, cmap='gray')\n",
    "            ax.axis('off')\n",
    "\n",
    "            # --- Add the score as text onto the image ---\n",
    "            # The text is placed at coordinates (x=2, y=26) on the image\n",
    "            txt = ax.text(2, 26, f\"{score:.3f}\",\n",
    "                          color='white', fontsize=11, fontweight='bold')\n",
    "            # Add a black outline to the text for high visibility\n",
    "            txt.set_path_effects([PathEffects.withStroke(linewidth=3, foreground='black')])\n",
    "\n",
    "            if i == 0:\n",
    "                ax.set_title(f\"{frac*100:.0f}% Noise\")\n",
    "\n",
    "    fig.suptitle('Sample Images with DataRater Scores', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af47861-0e4a-466d-8260-13a4ef10f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_mnist_loaders(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231103c0-4f32-4962-be3f-b8d8bf214f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_rater_from_checkpoint(checkpoint_path, device='cpu'):\n",
    "    \"\"\"\n",
    "    Load DataRater model using the existing construct_model function.\n",
    "    \"\"\"\n",
    "    # Create model using the same constructor as training\n",
    "    model = construct_model('DataRater')\n",
    "    \n",
    "    # Load the saved state dictionary\n",
    "    state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Load the state dict into the model\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Set to evaluation mode and move to device\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e52ff-32a3-4c76-af53-539677e0b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"experiments/your_run_id/data_rater.pt\"  # Update this path\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "data_rater = load_data_rater_from_checkpoint(checkpoint_path, device)\n",
    "analyze_with_individual_corruption(trained_data_rater, test_loader, num_batches=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
